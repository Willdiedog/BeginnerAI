{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "牛顿法\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.牛顿法的应用方向\n",
    "牛顿法至少有两个应用方向\n",
    "- 求方程的根\n",
    "- 最优化\n",
    "\n",
    "牛顿法涉及到方程求导，所以下面的讨论均是在连续可微的前提下讨论的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.求解方程\n",
    "并不是所有的方程都有求根公式，或者求根公式很复杂，导致求解困难。利用牛顿法，可以迭代求解。原理是利用泰勒公式，在$x_0$处展开，且展开到一阶，即\n",
    "$$f(x)=f(x_0)+(x－x_0)f'(x_0)$$\n",
    "求解方程$f(x)=0$，即\n",
    "$$f(x_0)+(x-x_0)*f'(x0)=0$$\n",
    "求解$x=x_1=x_0－\\frac{f(x_0)}{f'(x_0)}$，因为这是利用泰勒公式的一阶展开，$f(x) = f(x_0)+(x－x_0)f'(x_0)$处并不是完全相等，而是近似相等，这里求得的$x_1$并不能让$f(x)=0$，只能说$f(x_1)$的值比$f(x_0)$更接近$f(x)=0$，于是乎，迭代求解的想法就很自然了，可以进而推出$x(n+1)=x(n)－\\frac{f(x(n)}{f'(x(n))}$，通过迭代，这个式子必然在$f(x^*)=0$的时候收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.最优化\n",
    "用目标函数的二阶泰勒展开近似该目标函数，通过求解这个二次函数的极小值来求解凸优化的搜索方向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.牛顿法推导\n",
    "目标函数$f(x)$在$x$处的二阶泰勒展开为：\n",
    "$$f(x+\\nu)) \\approx f(x)+\\nabla{f(x)}^T\\nu+\\frac{1}{2}\\nu^T\\nabla^2f(x)\\nu$$\n",
    "当$x$固定时，$\\nu$取多少可以使$f(x+\\nu)$最小呢？可以通过两边对$\\nu$求偏导来求得。使上式两边对$\\nu$求偏导\n",
    "$$\\frac{\\partial}{\\partial{\\nu}}f(x+\\nu)=\\nabla{f(x)}+\\nabla^2f(x)\\nu$$\n",
    "当$f(x+\\nu)$最小时，$f(x+\\nu)$对$\\nu$的偏导为零，则\n",
    "$$=\\nabla{f(x)}+\\nabla^2f(x)\\nu=0$$\n",
    "则有\n",
    "$$\\nu=-\\nabla^2f(x)^{-1}\\nabla{f(x)}$$\n",
    "将这个方向作为搜索方向，这个方向被称为Newton步径，即\n",
    "$$\\Delta{x_{nt}}=-\\nabla^2f(x)^{-1}\\nabla{f(x)}$$\n",
    "$\\nabla^2f(x)$即为函数$f(x)$的Hessian矩阵，由凸函数的Hessian矩阵的正定性可知，除$f(x)$到达极值点$\\nabla{f(x)}=0$外，有\n",
    "$$\\nabla{f(x)}^T\\Delta{x_{nt}}=-\\nabla{f(x)}^T\\nabla^2f(x)^{-1}\\nabla{f(x)}<0$$\n",
    "因此Newton步径是下降方向，这种方法就是牛顿法。牛顿法是二阶收敛的，而梯度下降法是一阶收敛。二阶其实相当于考虑了梯度的梯度，所以相对更快"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.Hessian范数下的最速下降方法\n",
    "Hessian矩阵定义的二次范数\n",
    "$$||u||_{\\nabla^2f(x)}=(u^T\\nabla^2f(x)u)^{\\frac{1}{2}}$$\n",
    "Newton步径是采用Hessian矩阵定义的二次范数导出的最速下降方法，者从零一个角度揭示了为什么Newton步径是好的搜索方向算法了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.优势\n",
    "在实际应用中，牛顿法往往比梯度下降法有更少的迭代次数。从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.拟牛顿法\n",
    "牛顿法需要计算目标函数Hessian矩阵的逆矩阵，运算复杂度太高，计算效率很低，尤其维数很大时。拟牛顿算法的核心思想用一个近似矩阵替代逆Hessian矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.等式约束的牛顿法\n",
    "等式约束凸优化问题\n",
    "$$\\begin{eqnarray}\n",
    "min& &f(x)\\\\\n",
    "s.t.& &Ax=b\n",
    "\\end{eqnarray}$$\n",
    "其中对应的$f(x)$是凸函数，等式约束的Newton法和无约束Newton法有两点不同：\n",
    "- 初始点必须可行，即$x_0 \\in domf, Ax_0=b$\n",
    "- Newton方向$\\Delta{x_{nt}}$是可行方向，即$A\\Delta{x_{nt}}=0$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
