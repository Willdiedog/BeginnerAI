{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "链式法则与反向传播算法\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.链式法则\n",
    "若函数$\\mu=\\phi(t),\\nu=\\psi(t)$，在点t可到，$z=f(\\mu,\\nu)$，那么就有\n",
    "$$\\frac{\\partial{z}}{\\partial{t}}=\\frac{\\partial{z}}{\\partial{\\mu}} \\bullet \\frac{\\partial{\\mu}}{\\partial{t}} + \\frac{\\partial{z}}{\\partial{\\nu}} \\bullet \\frac{\\partial{\\nu}}{\\partial{t}}$$\n",
    "其实就是\n",
    "$$\\frac{\\partial{f}}{\\partial{\\omega}}=\\frac{\\partial{f}}{\\partial{q}} \\bullet \\frac{\\partial{q}}{\\partial{\\omega}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.反向传播算法\n",
    "神经网络是一个模型，权值就是模型的参数，也就是模型需要学习的东西。而神经网络的连结方式、网络的层次、每层的节点数这些参数是人为事先设置的，这些参数叫做超参数。假设每个训练样本为$(\\overrightarrow{x}, \\overrightarrow{t})$，其中向量$\\overrightarrow{x}$是训练样本的特征，而\n",
    "$\\overrightarrow{t}$是样本的目标值<br/>\n",
    "![images](images/02_00_06_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.实例一\n",
    "函数$f(x,y,z)=(x+y)*z$，且x=-2,y=5,z=-4使用链式法则求出$\\frac{\\partial{f}}{\\partial{x}}\\frac{\\partial{f}}{\\partial{y}}\\frac{\\partial{f}}{\\partial{z}}$<br/>\n",
    "解:令$q=x+y,\\therefore f=q*z$<br/>\n",
    "前向计算:$q=x+y=-2+5=3,f=q*z=3*-4=-12$<br/>\n",
    "反向传播:\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial{f}}{\\partial{x}}&=&\\frac{\\partial{f}}{\\partial{q}} \\bullet \\frac{\\partial{q}}{\\partial{x}}=z \\bullet 1=-4\\\\\n",
    "\\frac{\\partial{f}}{\\partial{y}}&=&\\frac{\\partial{f}}{\\partial{q}} \\bullet \\frac{\\partial{q}}{\\partial{y}}=z \\bullet 1=-4\\\\\n",
    "\\frac{\\partial{f}}{\\partial{z}}&=&q=3\n",
    "\\end{eqnarray}$$\n",
    "![images](images/02_00_06_002.png)<br/>\n",
    "上图中，反向传播的起点的1是因为要求的是$\\frac{\\partial{f}}{\\partial{f}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.实例二\n",
    "![images](images/02_00_06_003.png)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.实例三\n",
    "![images](images/02_00_06_004.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.实例四\n",
    "$$Sigmoid=f(\\omega,x)=\\frac{1}{1+e^{-(\\omega_0x_0+\\omega_1x_1+\\omega_2)}}$$\n",
    "前向计算很简单，至于反向传播，可以把sigmoid函数拆分成如下小函数\n",
    "$$\\begin{eqnarray}\n",
    "f(x)=\\frac{1}{x} &\\Rightarrow& \\frac{\\partial{f}}{\\partial{x}}=-\\frac{1}{x^2} \\\\\n",
    "f_c(x)=c+x &\\Rightarrow& \\frac{\\partial{f}}{\\partial{x}}=1 \\\\\n",
    "f(x)=e^x &\\Rightarrow& \\frac{\\partial{f}}{\\partial{x}}=e^x\\\\\n",
    "f_a(x)=ax &\\Rightarrow& \\frac{\\partial{f}}{\\partial{x}}=a\n",
    "\\end{eqnarray}$$\n",
    "![images](images/02_00_06_005.png)<br/>\n",
    "-0.53是怎么来的，在前向传播中，q=1.37，然后求出$\\frac{f}{q}=\\frac{1}{1.37}=0.73$，这个就是最终的f的值，那么反向传播中，第一步就是求出$\\frac{\\partial{f}}{\\partial{q}}=-\\frac{1}{q^2}=-\\frac{1}{1.37*1.37}=-0.53$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
