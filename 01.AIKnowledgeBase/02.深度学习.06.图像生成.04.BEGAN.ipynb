{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.边界平衡生成对抗网络-BEGAN(Boundary Equilibrium Generative Adversarial Networks)\n",
    "## 9.1.主要贡献\n",
    "1. 提出了一种新的简单强大GAN，使用标准的训练方式，不加训练trick也能很快且稳定的收敛\n",
    "2. 对于GAN中G，D的能力的平衡提出了一种均衡的概念（GAN的理论基础就是goodfellow理论上证明了GAN均衡点的存在，但是一直没有一个准确的衡量指标说明GAN的均衡程度）\n",
    "3. 提出了一种收敛程度的估计，这个机制只在WGAN中出现过。作者在论文中也提到，他们的灵感来自于WGAN，在此之前只有wgan做到了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2.传统的GAN原理\n",
    "BEGAN的判别器使用的是auto-encoder结构，输入的是图片，输出的是经过编码解码后的图片。以往的GAN及其变种都是希望生成器生成的数据分布尽可能的接近真实数据的分布，当生成数据分布等同于真是数据分布时，我们就确定生成器G经过训练可以生成和真是数据分布相同的样本，即获得了生成足以以假乱真数据的能力，以从这一点出发，研究者们设计了各种损失函数去令G的生成数据分布尽可能接近真实数据分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3.BEGAN的原理\n",
    "BEGAN代替了这种估计概率分布方法，它不直接去估计生成分布$Pg$与真实分布$Px$的差距，进而设计合理的损失函数拉近他们之间的距离，而是估计分布的误差之间的距离，作者认为只要分布的的误差分布相近的话，也可以认为这些分布是相近的，也就是说如果我们认为A和B很相似，而B和C也很相似，那么我们就认为A和C也很相似。在训练中，A相当于训练数据$X$,B相当于判别器$D$对于数据$X$编码解码后的图像$D(X)$，C就相当于$D$以$G$的生成未输入的结果$D[G(z)]$，所以，如果$||D(X)-X||-||D(X)-D[G(z)]||$不断趋近于0，那么随着训练，$D(X)$就会不断的趋近于$X$,那么$D[G(z)]$就会接近于$D(X)$，那么岂不是就意味着$G(z)$的数据分布和$X$的分布几乎一样了，那么就说明G学到了生成数据的能力。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
