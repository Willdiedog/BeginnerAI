{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "逻辑回归问题\n",
    "===\n",
    "对于线性回归来说，预测的变量$y$是连续变量，现在我们来讨论分类问题。分类问题与回归问题不同之处在于，$y$的取值是少量的离散值。现在，我们先介绍二元分类（binary classification），也就是$y$只能取$0$或$1$。逻辑回归的思想就是利用Sigmoid函数的阈值只能在0和1之间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.线性模型之二分类问题-逻辑回归(Logistic)\n",
    "## 1.1.基本概念\n",
    "0-1事件就是一个事件发生的概率只有两种可能，我们很自然的联想到使用伯努利族分布对$y$建模，那么如果我们假设1发生的概率为p，那么0发生的概率就是1-p，用一个统一个公式来表示，就是$P\\{X=x\\}=p^x(1-p)^{1-x}$,定义事件1发生的几率为$odds=\\frac{p}{1-p}$,对数几率$z=ln(odds)$,那么可\n",
    "以推导出如下公式：\n",
    "$$P\\{X=x\\}=\\frac{1}{1+e^{-z}}$$\n",
    "令$\\varphi = ln\\frac{p}{1-p}$，有\n",
    "$$\\begin{eqnarray}\n",
    "e^{\\varphi}&=&\\frac{p}{1-p}\\\\\n",
    "&\\Rightarrow& p=\\frac{e^{\\varphi}}{1+e^{\\varphi}}\\\\\n",
    "&\\Rightarrow& p=\\frac{1}{1+e^{-\\varphi}}\n",
    "\\end{eqnarray}$$\n",
    "这里我们推出了Sigmoid函数.这是因为Logistic模型对问题的前置概率估计其实就是伯努利分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lineX = np.linspace(-6,6, 15)\n",
    "y=1/(1+np.e**(-lineX))\n",
    "\n",
    "plt.figure(figsize=(6,6), facecolor='white')\n",
    "plt.plot(lineX, y, 'r--')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.Logistic公式\n",
    "有\n",
    "$$h_{\\theta}(x)=g(\\theta^Tx)=\\frac{1}{1+e^{-\\theta^Tx}}$$\n",
    "求导有\n",
    "$$\\begin{eqnarray}\n",
    "g'(x)&=&(\\frac{1}{1+e^{-x}})'\\\\\n",
    "&=&\\frac{e^{-x}}{(1+e^{-x})^2}\\\\\n",
    "&=&\\frac{1}{1+e^{-x}} \\bullet \\frac{e^{-x}}{1+e^{-x}}\\\\\n",
    "&=&\\frac{1}{1+e^{-x}} \\bullet (1-\\frac{1}{1+e^{-x}})\\\\\n",
    "&=&g(x) \\bullet (1-g(x))\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4.似然函数\n",
    "假定$\\begin{cases}\n",
    "P(y=1|x;\\theta)=h_{\\theta}(x)\\\\\\\\\n",
    "P(y=0|x;\\theta)=1-h_{\\theta}(x)\n",
    "\\end{cases}$，那么就有\n",
    "$$p(y|x;\\theta)=(h_{\\theta}(x))^y(1-h_{\\theta}(x))^{1-y}$$\n",
    "那么似然函数\n",
    "$$L(\\theta)=p(\\overrightarrow{y}|X;\\theta)=\\prod_{i=1}^m[h_{\\theta}(x^{(i)})]^{y^{(i)}} \\bullet [1-h_{\\theta}(x^{(i)})]^{1-y^{(i)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5.对数似然函数\n",
    "$$\\begin{eqnarray}\n",
    "L(\\theta)&=&\\prod_{i=1}^m[h_{\\theta}(x^{(i)})]^{y^{(i)}} \\bullet [1-h_{\\theta}(x^{(i)})]^{1-y^{(i)}}\\\\\n",
    "&\\Rightarrow& \\ell(\\theta)=logL(\\theta)=\\sum_{i=1}^my^{(i)}logh_{\\theta}(x^{(i)})+(1-y^{(i)})log(1-h_{\\theta}(x^{(i)}))\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6.对数似然求偏导\n",
    "已知条件有：\n",
    "$$\\begin{cases}\n",
    "h_{\\theta}(x^{(i)})=g(\\theta^Tx^{(i)}) &(1)\\\\\\\\\n",
    "g'(z)=g(z) \\bullet (1-g(z)) &(2)\n",
    "\\end{cases}$$\n",
    "所以有:\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial{\\ell(\\theta)}}{\\partial{\\theta_j}}&=&\\sum_{i=1}^m[y^{(i)} \\bullet \\frac{1}{h_{\\theta}(x^{(i)})} \\bullet \\frac{\\partial{h_{\\theta}(x^{(i)})}}{\\partial{\\theta_j}} + (1-y^{(i)}) \\bullet -\\frac{1}{1-h_{\\theta}(x^{(i)})} \\bullet \\frac{\\partial{h_{\\theta}(x^{(i)})}}{\\partial{\\theta_j}}]\\\\\n",
    "&=&\\sum_{i=1}^m[\\frac{y^{(i)}}{h_{\\theta}(x^{(i)})}-\\frac{1-y^{(i)}}{1-h_{\\theta}(x^{(i)})}] \\bullet \\frac{\\partial{h_{\\theta}(x^{(i)})}}{\\partial{\\theta_j}}\\\\\n",
    "&\\Rightarrow& \\sum_{i=1}^m[\\frac{y^{(i)}}{g(\\theta^Tx^{(i)})}-\\frac{1-y^{(i)}}{1-g(\\theta^Tx^{(i)})}] \\bullet \\frac{\\partial{g(\\theta^Tx^{(i)})}}{\\partial{\\theta_j}} \\\\\n",
    "&\\Rightarrow& \\sum_{i=1}^m[\\frac{y^{(i)}}{g(\\theta^Tx^{(i)})}-\\frac{1-y^{(i)}}{1-g(\\theta^Tx^{(i)})}] \\bullet g(\\theta^Tx^{(i)}) \\bullet [1-g(\\theta^Tx^{(i)})] \\bullet \\frac{\\partial{\\theta^Tx^{(i)}}}{\\partial{\\theta_j}} \\\\\n",
    "&\\Rightarrow& \\sum_{i=1}^m[y^{(i)}(1-g(\\theta^Tx^{(i)})) - (1-y^{(i)})g(\\theta^Tx^{(i)})] \\bullet x_j^{(i)}\\\\\n",
    "&\\Rightarrow& \\sum_{i=1}^m[y^{(i)} - g(\\theta^Tx^{(i)})] \\bullet x_j^{(i)}\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7.参数学习\n",
    "$$\\theta_j:=\\theta_j+\\alpha\\sum_{i=1}^m(y^{(i)}-h_{\\theta}(x^{(i)}))x_j^{(i)}$$\n",
    "有了这个，就可以进行参数学习了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8.梯度上升法-梯度下降法的反方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.999999515279857\n"
     ]
    }
   ],
   "source": [
    "def Gradient_Ascent_test():\n",
    "    def f_prime(x_old):                                    #f(x)的导数\n",
    "        return -2 * x_old + 4\n",
    "    x_old = -1                                            #初始值，给一个小于x_new的值\n",
    "    x_new = 0                                            #梯度上升算法初始值，即从(0,0)开始\n",
    "    alpha = 0.01                                        #步长，也就是学习速率，控制更新的幅度\n",
    "    presision = 0.00000001                                #精度，也就是更新阈值\n",
    "    while abs(x_new - x_old) > presision:\n",
    "        x_old = x_new\n",
    "        x_new = x_old + alpha * f_prime(x_old)            #上面提到的公式\n",
    "    print(x_new)                                        #打印最终求解的极值近似值\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Gradient_Ascent_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9.总结\n",
    "我们发现这个式子和线性回归的形式是完全一样的，如果我们定义$h_{\\theta}(x)=\\theta{X}$，那么就是线性回归，如果我们定义$h_{\\theta}(x)=\\frac{1}{1+e^{-\\theta{x}}}$，那么就是logistic回归。Logistic回归中，我们假定模型服从的是二项分布，利用最大似然估计进行推导的；线性回归我们假定模型服从高斯分布，利用最大似然估计推导的；正是因为二项分布和高斯分布都是指数族分布，所以它们才能得到一样的参数学习法则其实Logistic回归是一个广义的线性模型，这是因为\n",
    "$$logit(p)=log\\frac{p}{1-p}=log\\frac{h_{\\theta}(x)}{1-h_{\\theta}(x)}=log(\\frac{\\frac{1}{1+e^{-\\theta^T{x}}}}{\\frac{e^{-\\theta^T{x}}}{1+e^{-\\theta^T{x}}}})=loge^{-\\theta^T{x}}=\\theta^Tx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.线性回归之多分类问题-Softmax回归\n",
    "利用线性模型来进行多分类，就是Softmax回归\n",
    "\n",
    "## 2.1.定义\n",
    "设样本为一个m行的记录$X=\\{\\overrightarrow{x_1},\\overrightarrow{x_2},...,\\overrightarrow{x_n}\\}$, 共有K的类别，那么存在这么K个$\\Theta$向量$\\overrightarrow{\\theta_1},\\overrightarrow{\\theta_2},...,\\overrightarrow{\\theta_K}$。令$Z=\\Theta^TX$，且\n",
    "设$\\varphi=\\frac{1}{1+e^{-Z}}$，则有$\\varphi=\\frac{1}{1+e^{-\\Theta^TX}}$\n",
    "- 如果K=2，那么就是Logistic回归。分类为$y \\in \\{0, 1\\}$，带入$\\varphi$函数后，总能求的一个0~1之间的值，我们用0.5做分界点，大于0.5的就是分类1，否则就是分类0\n",
    "- 如果K>2，那么就是softmax回归\n",
    "\n",
    "## 2.2.似然函数\n",
    "令$C_i=e^{\\overrightarrow{\\theta_i}^T\\overrightarrow{x_i}}$，则第i行的概率为\n",
    "$$p(c=k|x;\\theta)=\\frac{e^{\\theta_k^Tx}}{\\sum_{i=1}^Ke^{\\theta_i^Tx}}, k=1,2,...,K$$\n",
    "似然函数为\n",
    "$$L(\\theta)=\\prod_{i=1}^m\\prod_{k=1}^Kp(c=k|x^{(i)};\\theta)^{y_k^{(i)}}=\\prod_{i=1}^m\\prod_{k=1}^K[\\frac{e^{\\theta_k^Tx}}{\\sum_{i=1}^Ke^{\\theta_i^Tx}}]^{y_k^{(i)}}$$\n",
    "\n",
    "## 2.3.对数似然  \n",
    "$$J_m(\\theta)=lnL(\\theta)=\\sum_{i=1}^m\\sum_{k=1}^Ky_k^{(i)} \\bullet (\\theta_k^Tx^{(i)}-ln\\sum_{i=1}^Ke^(\\theta_i^Tx^{(i)}))$$\n",
    "\n",
    "## 2.4.损失函数\n",
    "$$J(\\theta)=\\sum_{k=1}^Ky_k \\bullet (\\theta_k^Tx-ln\\sum_{i=1}^Ke^{\\theta_i^Tx})$$\n",
    "\n",
    "## 2.5.随机梯度\n",
    "$$\\frac{\\partial{J(\\theta)}}{\\partial{\\theta_k}}=(y_k-p(y_k|x;\\theta)) \\bullet x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.一般线性问题的建模过程\n",
    "- 根据训练集$x^{(i)},y^{(i)}$选择概率分布模型，参数为$\\phi$；\n",
    "- 将该分布写为指数分布族的形式，参数为$\\eta$；\n",
    "- 可以得到正则响应函数$g(\\eta)=\\mathrm{E}[T(y);\\eta]$；\n",
    "- 将$\\eta=\\theta^Tx$带入正则响应函数得到假设函数$h_\\theta(x)=g(\\theta^Tx)$；\n",
    "- 根据模型的概率解释得到似然函数$L(\\theta)=p(y^{(i)}\\mid x^{(i)};\\theta)$（根据假设函数得到）；\n",
    "- 取合适的$\\theta$使似然函数最大化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.Logistic回归的一般过程\n",
    "Logistic回归的一般过程：\n",
    "- 收集数据：采用任意方法收集数据。\n",
    "- 准备数据：由于需要进行距离计算，因此要求数据类型为数值型。另外，结构化数据格式则最佳。\n",
    "- 分析数据：采用任意方法对数据进行分析。\n",
    "- 训练算法：大部分时间将用于训练，训练的目的是为了找到最佳的分类回归系数。\n",
    "- 测试算法：一旦训练步骤完成，分类将会很快。\n",
    "- 使用算法：首先，我们需要输入一些数据，并将其转换成对应的结构化数值；接着，基于训练好的回归系数，就可以对这些数值进行简单的回归计算，判定它们属于哪个类别；在这之后，我们就可以在输出的类别上做一些其他分析工作。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
