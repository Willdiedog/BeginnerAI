WGAN机器增强版本
===
WGAN=>Wasserstein Generative Adversarial Networks

# 1.原始GAN究竟出了什么问题
原始GAN中判别器要最小化如下损失函数，尽可能把真实样本分为正例，生成样本分为负例：
$$-\mathbb{E}\_{x\sim P_r}\[\log D(x)] - \mathbb{E}\_{x\sim P_g}\[\log(1-D(x))] \tag{1}$$
其中$P_r$是真实样本分布，$P_g$是由生成器产生的样本分布。对于生成器，Goodfellow一开始提出来一个损失函数，后来又提出了一个改进的损失函数，分别是
$$\begin{eqnarray*}
\mathbb{E}\_{x\sim P_g}\[\log(1-D(x))]\tag{2}\\
\mathbb{E}\_{x\sim P_g}\[- \log D(x)]\tag{3}
\end{eqnarray*}$$
后者在WGAN两篇论文中称为“the - log D alternative”或“the - log D trick”