{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "凸优化\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.凸优化\n",
    "## 1.1.什么是凸优化\n",
    "不严格的说，凸优化就是在标准优化问题的范畴内，要求目标函数和约束函数是凸函数的一类优化问题\n",
    "\n",
    "## 1.2.凸优化的重要性\n",
    "- 其应用非常广泛，机器学习中很多优化问题都要通过凸优化来求解；\n",
    "- 在非凸优化中，凸优化同样起到重要的作用，很多非凸优化问题，可以转化为凸优化问题来解决；\n",
    "- 凸优化问题可以看作是具有成熟求解方法的问题，而其他优化问题则未必。\n",
    "\n",
    "## 1.3.凸优化的知识体系\n",
    "凸优化包括以下五个方面的知识\n",
    "- 凸集\n",
    "- 凸函数\n",
    "- 凸优化\n",
    "- 凸优化问题求解\n",
    "- 对偶问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.凸集\n",
    "## 2.1.直线上的点\n",
    "$\\forall x, y \\in R^n$且$x \\neq y$，那么\n",
    "$$z=\\theta{x}+(1-\\theta)y,&emsp;\\theta \\in R$$\n",
    "是一条穿越x和y的直线\n",
    "- $\\theta=0$时，$z=y$\n",
    "- $\\theta=1$时，$z=x$\n",
    "- $0 \\leq \\theta \\leq 1$时，z是x和y之间的线段上的点\n",
    "- $\\theta < 0$或$\\theta > 1$时，z是x和y线段之外的点\n",
    "\n",
    "## 2.2.定义\n",
    "凸集用来定义目标函数和约束函数的定义域。$\\forall x,y \\in C, 0 \\leq \\theta \\leq 1$有$\\theta{x}+(1-\\theta)y \\in C$的集合称为凸集\n",
    "\n",
    "## 2.3.典型的凸集\n",
    "### 2.3.1.线段、射线、直线\n",
    "\n",
    "### 2.3.2.超平面和半空间\n",
    "- 超平面hyperplane:$\\{x|a^Tx=b\\}$\n",
    "- 半空间halfspace:$\\{x|a^T \\leq b\\},\\{x|a^Tx \\geq b\\}$\n",
    "\n",
    "a就是平面的法向量\n",
    "![images](images/00_03_01_001.png)\n",
    "\n",
    "超平面分离定理：两个不相交的凸集，存在一个超平面将其分离\n",
    "\n",
    "### 2.3.3.仿射集\n",
    "多面体是有限个半空间和超平面的交集$P=\\{x|a_j^Tx \\leq b, c_i^Tx=d_i\\}$\n",
    "- 仿射集(如超平面、直线、射线、线段、班空间都是多面体)\n",
    "- 多面体是凸集\n",
    "\n",
    "![images](images/00_03_01_002.png)\n",
    "\n",
    "### 2.3.4.欧几里得球、范数球、椭球等\n",
    "\n",
    "### 2.3.5.凸锥、范数锥\n",
    "\n",
    "## 2.4.凸集的保凸运算\n",
    "### 2.4.1.集合交运算\n",
    "### 2.4.2.仿射变换\n",
    "函数$f=Ax+b,A \\in R^{m*n}, b \\in R^m$的形式，称函数是仿射的；即线性函数加常数的形式(仿射可以伸缩、平移、投影)\n",
    "\n",
    "若f是仿射变换，$f:R^n \\rightarrow R^m, f(S)=\\{f(x)|x \\in S\\}$\n",
    "- 若S为凸集，则$f(S)$为凸集\n",
    "- 若$f(S)$为凸集，则S为凸集\n",
    "\n",
    "### 2.4.3.透视变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.凸函数\n",
    "## 3.1.定义\n",
    "函数$f:R^n \\to R$的定义域$domf$是凸集，并且对于$\\forall x,y \\in domf$和$\\forall \\theta, 0 \\leq \\theta \\leq 1$有\n",
    "$$f(\\theta{x}+(1-\\theta)y) \\leq \\theta{f(x)}+(1-\\theta)f(y)$$\n",
    "则称函数$f$是凸的。<br/>\n",
    "![images](images/00_03_01_003.png)<br/>\n",
    "- 凸函数图像的上方区域，一定是凸集\n",
    "- 一个函数图像的上方区域为凸集，则该函数是凸函数\n",
    "\n",
    "## 3.2.性质\n",
    "### 3.2.1.一阶条件\n",
    "可微函数$f$是凸函数的充要条件是\n",
    "$$\\begin{cases}\n",
    "定义域domf是凸集\\\\\\\\\n",
    "\\forall x,y \\in domf,有f(y) \\geq f(x) + \\nabla{f(x)}^T(y-x)\n",
    "\\end{cases}$$\n",
    "\n",
    "### 3.2.2.二阶条件\n",
    "函数$f$的二阶偏导称为函数$f$的Hessian矩阵。对于函数$f$的定义域$domf$内任意一点，其Hessian矩阵存在，则函数$f$是凸函数的充要条件是，其Hessian矩阵是半正定阵。也即，对于所有$x \\in domf$有$\\nabla^2f(x) \\geq 0$。对于R上的函数，可以简化为$f''(x) \\geq 0$\n",
    "\n",
    "### 3.2.3.典型的凸函数\n",
    "- 线性函数和仿射函数\n",
    "- 指数函数\n",
    "- 负熵\n",
    "- 范数\n",
    "\n",
    "### 3.2.4.凸函数的保凸运算\n",
    "非负加权求和、复合仿射映射、逐点最大和逐点上确界、复合等\n",
    "\n",
    "## 3.3.Jensen不等式\n",
    "Jensen当年提出的不等式相当简单，$f$是凸函数，则\n",
    "$$f(\\frac{x+y}{2}) \\leq \\frac{f(x)+f(y)}{2}$$\n",
    "Jensen不等式，又叫做詹森不等式，以丹麦数学家约翰·詹森(Johan Jensen)命名\n",
    "\n",
    "### 3.3.1.常规形式\n",
    "上述式子是Jensen不等式的常规形式，还可以扩展至更多点的凸组合：如果函数$f$是凸函数，$x_i,...,x_k \\in domf, \\theta_1,...,\\theta_k \\geq 0$且$\\theta_1+...+\\theta_k=1$，则下式成立\n",
    "$$f(\\theta_1x_1+...+\\theta_kx_k) \\leq \\theta_1f(x_1)+...+\\theta_kf(x_k)$$\n",
    "此不等式也可以扩展至无穷项和\n",
    "\n",
    "### 3.3.2.概率形式\n",
    "上式中的$\\theta_1,...,\\theta_k$可以看做是概率分布，所以，如果函数$f$是凸函数，$x_i,...,x_k \\in domf$，$p_1,...,p_k$是概率分布，则\n",
    "$$f(p_1x_1+...+p_kx_k) \\leq p_1f(x_1)+...+p_kf(x_k)$$\n",
    "如果是连续概率分布，那么如果在$S \\subseteq domf$上$p(x) \\geq 0$是随机事件x的概率密度，则有$\\int_Sp(x)dx=1$，则当相应积分存在时，有\n",
    "$$f(\\int_Sp(x)xdx) \\leq \\int_Sf(x)p(x)dx$$\n",
    "写成期望的形式\n",
    "$$f(Ex) \\leq Ef(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.凸优化及其问题求解\n",
    "## 4.1.凸优化的优势\n",
    "凸优化之所以如此重要，是因为凸优化的重要特性：**凸优化的任意局部最优解也是全局最优解**\n",
    "\n",
    "## 4.2.标准优化问题\n",
    "$$\\begin{eqnarray}\n",
    "min& &f_0(x)\\\\\n",
    "s.t.& &f_i(x) \\leq 0, i=1,...,m\\\\\n",
    "& &h_i(x)=0, i=1,...,p\n",
    "\\end{eqnarray}$$\n",
    "表示在所有满足$f_i(x) \\leq,i=1,...,m$及$h_i(x)=0,i=1,...,p$的$x$中，找出使得$f_0(x)$最小的$x$.这里$x \\in R^n$称为问题的优化变量，函数$f_0:R^n \\to R$称为目标函数，不等式$f_i(x) \\leq 0$称为不等式约束，相应的$f_i:R^n \\to R,i=1,2,...,m$称为不等式约束函数，方程组$h_i(x)=0$称为等式约束，相应的$h_i:R^n \\to R,i=1,2,...,p$称为等式约束。如果没有约束，即$m=p=0$，称为无约束问题，那么对目标和说有约束函数有定义的点的集合\n",
    "$$\\delta=\\bigcap_{i=0}^mdomf_i \\cap \\bigcap_{j=1}^pdomh_j$$\n",
    "称为优化问题的定义域\n",
    "- 优化变量：$x \\in R^n$\n",
    "- 不等式约束：$f_i{x} \\leq 0$\n",
    "- 等式约束：$h_j(x)=0$\n",
    "- 无约束优化：$m=p=0$\n",
    "\n",
    "若干概念\n",
    "- 优化问题的域：$f(x)$和$h(x)$的定义域的交集\n",
    "- 可行点：如果x在优化问题的域上，切满足约束条件\n",
    "- 所有的可行点的集合叫做可行域\n",
    "- 最优化的值就是求$f(x)$的下确界\n",
    "\n",
    "## 4.3.凸优化问题\n",
    "$$\\begin{eqnarray}\n",
    "min& &f_0(x)\\\\\n",
    "s.t.& &f_i(x) \\leq 0, i=1,...,m\\\\\n",
    "& &h_i(x)=0, i=1,...,p\n",
    "\\end{eqnarray}$$\n",
    "其中，$f_i(x),i=0,...,m$是凸函数。$x^* \\in X$是可微函数$f_0$的最优解，当且仅当$\\nabla{f_0(x^*)^T(y-x^*)} \\geq 0, \\forall y \\in X$\n",
    "\n",
    "## 4.4.最优性准则\n",
    "### 4.4.1.无约束凸优化的最优性准则\n",
    "我们知道，当$m=p=0$的时候，叫做无约束凸优化问题，那么$x^* \\in X$是可微函数$f$的最优解的充要条件是$\\nabla{f(x^*)}=0$\n",
    "\n",
    "### 4.4.2.等式约束凸优化的最优化准则\n",
    "当$m=0$时，叫做等式约束，那么$x^* \\in X$是可微函数$f$的最优解的充要条件是存在$\\nu=[\\nu_1,...,\\nu_p]^T \\in R^p$，使得\n",
    "$$\\nabla{f_0(x^*)} + \\sum_{i=1}^p\\nu_i\\alpha_i=0$$\n",
    "其中$\\alpha_i \\in R^n$，这个可以通过Lagrange对偶函数的KKT条件证明的到。\n",
    "\n",
    "将等式约束凸优化问题描述为矩阵形式\n",
    "$$\\begin{split}\n",
    "min&&emsp;f(x)\\\\\\\\\n",
    "s.t.&&emsp;Ax=b\n",
    "\\end{split}$$\n",
    "对应的，$x^* \\in X$是可微函数$f$的最优解的充要条件是存在$\\nu \\in R^p$，使得\n",
    "$$\\nabla{f(x^*)}+A^T\\nu=0$$\n",
    "其中$A \\in R^{p*n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.无约束凸优化问题求解\n",
    "## 5.1.解析解\n",
    "对于少数一些简单的凸优化问题，可以利用最优性准则通过解析来求解。但对于大多数凸优化问题来讲，是没有办法通过解析来求解的\n",
    "\n",
    "## 5.2.下降方法\n",
    "下降方法将产生一个优化点列$x^{(k)},k=1,...,$其中\n",
    "$$x^{(k+1)}=x^{(k)}+t^{(k)}\\Delta{x}^{(k)},t^{(k)}>0$$\n",
    "使得\n",
    "$$f(x^{(k+1)})<f(x^{(k)})$$\n",
    "$\\Delta{x}^{(k)}$被称为搜索方向，$t^{(k)}$被称为步长。由凸函数的一阶条件可知，下降方法中的搜索方向必须满足：\n",
    "$$\\nabla{f(x^{(k)})}^T\\Delta{x}^{(k)}<0$$\n",
    "即搜索方向和扶梯度方向的夹角必须是锐角<br/>\n",
    "下降方法中，有两个问题需要解决：确定搜索步长和确定搜索方向。\n",
    "- 确定搜索步长的方法：固定步长搜索、精确直线搜索、回溯直线搜索\n",
    "- 确定搜索方向的方法：梯度下降法、最速下降法、牛顿法\n",
    "\n",
    "### 5.2.1 确定步长的方法之固定步长搜索\n",
    "步长值根据经验设定，为了防止算法震荡，值应当较小。优点：直观、简单；缺点：收敛速度慢\n",
    "\n",
    "### 5.2.2 确定步长的方法之精确直线搜索\n",
    "搜索方向确定时，精确直线搜索步长沿着射线$\\\\{x+t\\Delta{x}|t \\geq 0\\\\}$，求解如下优化问题\n",
    "$$t=argmin_{s \\geq 0}f(x+s\\Delta{x})$$\n",
    "当其优化成本比较低时，适合精确直线搜索\n",
    "\n",
    "### 5.2.3 确定步长的方法之回溯直线搜索\n",
    "比较常用的是回溯直线搜索，大概思路是，用迭代方法求得的步长只要能使目标函数有足够的减少即可。可以参考[回溯直线搜索](01.基础-03.凸优化-02.回溯直线搜索.ipynb)的介绍\n",
    "\n",
    "### 5.2.4.调整搜索方向的方法之梯度下降法\n",
    "下降方法中必须满足，搜索方向和负梯度成锐角。用负梯度作为搜索方向就自然而然了，即\n",
    "$$\\Delta(x)=-\\nabla{f(x)}$$\n",
    "可以参考[梯度下降法](01.基础-03.凸优化-03.梯度下降法.ipynb)的介绍\n",
    "\n",
    "### 5.2.5.调整搜索方向的方法之最速下降法\n",
    "利用目标函数的一阶泰勒展开近似优化过程，进而确定学习方向。可以参考[最速下降法](01.基础-03.凸优化-04.最速下降法.ipynb)的介绍\n",
    "\n",
    "### 5.2.6.调整搜索方向的方法之牛顿法\n",
    "利用目标函数的二阶泰勒展开近似表示目标函数，通过求解这个二次函数的极小值来确定搜索方向.可以参考[牛顿法](01.基础-03.凸优化-05.牛顿法.ipynb)的介绍\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.等式约束凸优化问题的求解\n",
    "## 6.1.通过消除等式求解\n",
    "任何等式约束优化问题都可以通过消除等式约束转化为等价的无约束优化问题，然后利用无约束的方法求解\n",
    "\n",
    "## 6.2.通过Lagrange对偶问题求解\n",
    "利用无约束优化问题求解对偶问题，然后从对偶解中复原等式约束问题的解.可以参考[拉格朗日对偶问题](01.基础-03.凸优化-06.拉格朗日对偶问题.ipynb)的介绍\n",
    "\n",
    "## 6.3.等式约束的牛顿法求解\n",
    "可以参考[牛顿法](01.基础-03.凸优化-05.牛顿法.ipynb)的介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.不等式约束凸优化问题求解\n",
    "## 7.1.通过Lagrange对偶问题求解\n",
    "利用无约束优化问题求解对偶问题，然后从对偶解中复原不等式约束问题的解，可以参考[拉格朗日对偶问题](01.基础-03.凸优化-06.拉格朗日对偶问题.ipynb)的介绍\n",
    "\n",
    "## 7.2.内点法\n",
    "主要思路：引进的惩罚函数的在可行域的边界上设置障碍，使求解的迭代过程始终在可行域内部进行"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
